{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook aims to create a matrix for logistic regression. It follows the 'all_demographic_no_timewindow.ipynb' notebook and will process SNOMED/Phecode mapping.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "# --- Load data ---\n",
    "condition_data = pd.read_csv('condition_dataset.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SNOMED to ICD mapping --- \n",
    "snomed2icd = pd.read_csv('snomed_icd_mapping.csv',dtype={'SNOMED': str, 'ICD10':str})\n",
    "snomed2icd = snomed2icd.rename(columns ={'SNOMED':'source_concept_code',\n",
    "                                         'ICD10CM':'ICDcode'}) # Ensure column name is matching\n",
    "\n",
    "# Select interested columns\n",
    "df_condition_all = condition_data[['person_id','standard_concept_code','source_concept_code','source_vocabulary','condition_start_datetime']]\n",
    "\n",
    "# Subset records that already use ICD codes\n",
    "df_condition_icd = df_condition_all.loc[df_condition_all['source_vocabulary'].isin(['ICD10CM', 'ICD9CM'])]\n",
    "\n",
    "# Subset records that use SNOMED codes\n",
    "df_condition_snomed = df_condition_all.loc[dataset_condition_df['source_vocabulary'] == 'SNOMED' ]\n",
    "df_condition_snomed = df_condition_snomed.reset_index(drop = True)\n",
    "\n",
    "# Map SNOMED codes to ICD using the reference table\n",
    "df_condition_snomed_mapped = df_condition_snomed.merge(snomed2icd, how='left', on = 'source_concept_code')\n",
    "\n",
    "# Remove records without ICD mapping\n",
    "df_condition_snomed_mapped = df_condition_snomed_mapped.dropna(subset=['ICDcode'])\n",
    "\n",
    "# Standardize ICD column format for both sources\n",
    "df_condition_icd.loc[:, 'ICDcode'] = df_condition_icd['source_concept_code']\n",
    "df_condition_icd.loc[:, 'ICDsource'] = df_condition_icd['source_vocabulary']\n",
    "\n",
    "# Concatenate both sources into a unified ICD-coded dataset\n",
    "df_condition_with_icd= pd.concat([df_condition_icd,df_condition_snomed_mapped],ignore_index=True)\n",
    "df_condition_with_icd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ICD to Phecode mapping ---\n",
    "df_icd9_to_phe = pd.read_csv('ICD_9CM_phecode.csv', dtype={'Phecode': str, 'ICD': str})\n",
    "df_icd10_to_phe = pd.read_csv('ICD_10CM_phecode.csv', dtype={'Phecode': str, 'ICD': str})\n",
    "\n",
    "# Standardize column names\n",
    "df_icd9_to_phe = df_icd9_to_phe.rename(columns={'ICD': 'ICDcode'})\n",
    "df_icd10_to_phe = df_icd10_to_phe.rename(columns={'ICD': 'ICDcode'})\n",
    "\n",
    "# Subset ICD9-coded conditions\n",
    "df_condition_icd9 = df_condition_with_icd[\n",
    "    df_condition_with_icd['source_vocabulary'] == 'ICD9CM'\n",
    "]\n",
    "\n",
    "# Subset ICD10-coded conditions, including SNOMED-mapped\n",
    "df_condition_icd10 = df_condition_with_icd[\n",
    "    (df_condition_with_icd['source_vocabulary'] == 'ICD10CM') |\n",
    "    (df_condition_with_icd['source_vocabulary'] == 'SNOMED')\n",
    "]\n",
    "# Map ICD-9-CM codes to Phecodes\n",
    "df_phe_icd9 = df_condition_icd9.merge(df_icd9_to_phe, how='left', on='ICDcode')\n",
    "\n",
    "# Map ICD-10-CM codes to Phecodes\n",
    "df_phe_icd10 = df_condition_icd10.merge(df_icd10_to_phe, how='left', on='ICDcode')\n",
    "\n",
    "# Concatenate all Phecode-mapped condition records\n",
    "df_phe_condition = pd.concat([df_phe_icd9, df_phe_icd10])\n",
    "\n",
    "# Identify unmapped ICD codes\n",
    "df_unmapped_icd = df_phe_condition[df_phe_condition['Phecode'].isna()]\n",
    "df_unmapped_icd = df_unmapped_icd[['ICDcode', 'ICDsource']].drop_duplicates()\n",
    "print('ICD codes not mapped to any Phecode:', df_unmapped_icd.ICDcode.unique())\n",
    "\n",
    "# Remove unmapped records and duplicates\n",
    "df_phe_condition_mapped = df_phe_condition.dropna(subset=['Phecode'])\n",
    "df_phe_condition_mapped = df_phe_condition_mapped.drop_duplicates()\n",
    "\n",
    "print('Number of unique Phecodes:',len(set(df_phe_condition_mapped['Phecode'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phe_condition_mapped.to_csv('df_phe_condition_mapped.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
